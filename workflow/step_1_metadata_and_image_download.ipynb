{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Metadata Collection and Image Download\n",
    "\n",
    "In this section, we will work to extract, save, and structure the relevant metadata from the DC image collection created in the last section, creating a JSON file with all the relevant metadata. Using the metadata, we will also download and save the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Imports\n",
    "\n",
    "Before we get started, let's import some libraries and modules that that are specific to this step in the workflow. We'll also import the libraries and modules important to the overall process from workflow_helpers.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from workflow_helpers import *\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_instances = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Collection CSV and Access Collection Links\n",
    "\n",
    "In this step, we'll assign the filepath of the collection data we want to work with to a variable. For simplicity, we'll call this variable \"file\". \n",
    "\n",
    "Please note that you may use any data storage format that you are comfortable with, such as JSON. However, our helper function is written based on the data storage format that our team is most likely to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the filepath to the csv file with the collection information\n",
    "file = \"jfp-collections-starter-collections.csv\"\n",
    "#using the function from the helper file to read in the csv\n",
    "collection = read_in_collection_csv_for_links(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate through the data to become familar with it, verify that it is in a format we can work with, and that it has all the information we expect.\n",
    "\n",
    "If your collection data is larger than what we have here, you can limit the output from the collection by tweaking our code as shown below, where 'n' is the number of items you want to return from the collection list:\n",
    "\n",
    "\n",
    "To append each link without the CSV header, we'll iterate through our \"collection\" list variable from row 1, where row 0 is the header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffCollection Name', 'Collection Link', 'Notes', 'Objects of Interest']\n",
      "['National Photo Company Collection', 'https://www.loc.gov/collections/national-photo-company/', 'Filter by restriction: \"right_information\" and \"rights_advisory\"', 'People, Animals, Landmarks, Vehicles']\n",
      "['Highsmith (Carol M.) Archive', 'https://www.loc.gov/collections/carol-m-highsmith/', 'Would need to be filtered by place since it captures projects outside of D.C. Given how Highsmith organized/labeled these images, we could (for the most part) safely do a \"if D.C. in XXX:\" from the \"subject_headings\" field or \"title\" field (the latter seems easier as it\\'s less nested).\\n\\nFilter by restriction: \"right_information\" and \"rights_advisory\"', 'Landscape, Landmarks, Roads']\n",
      "['Free to Use', 'https://www.loc.gov/free-to-use/', 'Filter for D.C. by \"title\" and \"subhect_headings\"\\nFilter by restriction: \"right_information\" and \"rights_advisory\"\\n\\n', 'Animals, People']\n"
     ]
    }
   ],
   "source": [
    "#making sure the data is as expected\n",
    "for row in collection:\n",
    "    print(row)\n",
    "\n",
    "#isolating  and saving the collection links\n",
    "collection_links = []\n",
    "\n",
    "for link in collection[1:]:\n",
    "    collection_links.append(link[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've saved the collection links, let's access the JSON information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list stores the json response for each collection\n",
    "json_responses = []\n",
    "\n",
    "for link in collection_links:\n",
    "        #using the access_and_store_json function from the helper file\n",
    "        json_response = access_and_store_json(link)\n",
    "        json_responses.append(json_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next step, we will optionally download the JSON files for each collection for easier inspection of the structure and organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(collection_links)):\n",
    "    name = collection[index+1][0].lower().replace(\" \", \"_\")\n",
    "    with open(f\"{name}.json\", 'w') as f:\n",
    "        json.dump(json_responses[index], f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Metadata\n",
    "\n",
    "Now, we will be creating a new JSON file with the relevant metadata we want to save about each image. To demonstrate this, we will be filtering out and collecting images from our chosen collections that include \"DC\" as a topic, and saving select metadata for reference for each image.\n",
    "\n",
    "For our purposes, we've selected to save the following: the resource ID, the title, the image URL, the subjects, the date, the contributor names, the description, the alt text (if available), the collection name (source_collection), and the original format.\n",
    "\n",
    "**The structure of the JSON for collections with alt text is different from that of collections without alt text, so we will have to extract the metadata slightly differently.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_responses_no_alt = [] #A list to store the JSON information from collections with no alt text\n",
    "json_responses_alt = [] #A list to store the JSON information from collections with alt text\n",
    "\n",
    "for link in collection_links:\n",
    "    try:\n",
    "        response = access_and_store_json(link)\n",
    "        if response[\"site_type\"] == \"collections\":\n",
    "            json_responses_no_alt.append(response)\n",
    "        elif response[\"site_type\"] == \"free-to-use\": \n",
    "        #the free-to-use collection has been specially curated and given alt text\n",
    "            json_responses_alt.append(response)\n",
    "    except:\n",
    "        print('try again')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the collections with alt text. We'll begin by getting the urls of each image in the collections with alt text so we can use them for get requests to get the necessary metadata.\n",
    "\n",
    "The Free to Use and Reuse collection is specifically curated and has alt-text, whereas most other Library collections do not.\n",
    "\n",
    "As such, we cannot access the image URLs in the same way. We need to find a way to separate collections with alt-text and those without, and store their JSON responses into separate variables.\n",
    "\n",
    "There are many ways to do this at scale, but some customization will be needed regardless.\n",
    "\n",
    "We opted to sort the collection via key lookup, using ``` ['site_type'] ``` as a way to sort the collections since only one of these collections have alt-text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list of partial URLs extracted from the JSON data, structure similar \n",
    "#to the following: '/resource/highsm.12695/'.\"\"\"\n",
    "unformatted_links = []\n",
    "\n",
    "#A list of URLs without the JSON filter parameter, but with the root of the URL: 'https://www.loc.gov'.\n",
    "partially_formatted_links = []\n",
    "\n",
    "#A list of fully formatted urls, with root and JSON filter applied.\n",
    "formatted_links = []\n",
    "\n",
    "#A holding list for using try and except.\n",
    "error_links = []\n",
    "\n",
    "#A list of URLs from the data that already had an 'https://' construction and cannot have the\n",
    "#JSON filter parameted applied.\n",
    "research_guide_not_image_collection = []\n",
    "\n",
    "for collection_data in json_responses_alt:\n",
    "    results = collection_data['pages']\n",
    "    for result in results:\n",
    "        get_children = result['children'][1:]\n",
    "        for group in get_children:\n",
    "            set = group['set']['items']\n",
    "            for item in set:\n",
    "                link = item['link']\n",
    "                if 'alt' in item.keys():\n",
    "                    alt = item['alt'] \n",
    "                    #saving alt text for easier retrieval to built the JSON file later\n",
    "                else:\n",
    "                    alt = \"NA\"\n",
    "                to_append = []\n",
    "                to_append.append(link)\n",
    "                to_append.append(alt)\n",
    "                unformatted_links.append(to_append)\n",
    "\n",
    "for link in unformatted_links:\n",
    "    root = 'https://www.loc.gov'\n",
    "    try:\n",
    "        if 'https://' not in link[0]:\n",
    "            y = root + link[0]\n",
    "            to_append = []\n",
    "            to_append.append(y)\n",
    "            to_append.append(link[1])\n",
    "            partially_formatted_links.append(to_append)\n",
    "        if 'https://' in link[0]:\n",
    "            research_guide_not_image_collection.append(link)\n",
    "    except:\n",
    "        error_links.append(link)\n",
    "\n",
    "for link in partially_formatted_links:\n",
    "    try:\n",
    "        if '?' not in link[0]:\n",
    "            x = link[0] + '?fo=json'\n",
    "            to_append = []\n",
    "            to_append.append(x)\n",
    "            to_append.append(link[1])\n",
    "            formatted_links.append(to_append)\n",
    "        if '?' in link[0]:\n",
    "            #Image URL may already have a filter, so we need to append the JSON filter to a existing filter.\n",
    "\n",
    "            x =  link[0] + '&fo=json'\n",
    "            to_append = []\n",
    "            to_append.append(x)\n",
    "            to_append.append(link[1])\n",
    "            formatted_links.append(to_append)\n",
    "    except:\n",
    "        error_links.append(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the links, we can perform get requests, filter for relevant DC images, and store the relevant metadata.\n",
    "\n",
    "In the collections with no alt text, we'll be able to do this directly from the json we already have, without having to use get requests on individual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_version_', 'access_restricted', 'aka', 'call_number', 'campaigns', 'contributor_names', 'contributors', 'control_number', 'created', 'created_published', 'created_published_date', 'date', 'dates', 'description', 'digital_id', 'digitized', 'display_offsite', 'extract_timestamp', 'extract_urls', 'format', 'format_headings', 'genre', 'group', 'hassegments', 'id', 'image_url', 'index', 'item', 'language', 'languages', 'library_of_congress_control_number', 'link', 'location', 'location_city', 'location_country', 'location_county', 'location_state', 'locations', 'locations_city', 'locations_country', 'locations_county', 'locations_state', 'marc', 'medium', 'medium_brief', 'mime_type', 'modified', 'notes', 'number', 'number_carrier_type', 'number_former_id', 'number_lccn', 'number_source_modified', 'online_format', 'original_format', 'other_control_numbers', 'other_formats', 'other_title', 'partof', 'place', 'related', 'repository', 'reproduction_number', 'reproductions', 'resource_links', 'resources', 'rights', 'rights_advisory', 'rights_information', 'score', 'shard', 'shelf_id', 'site', 'sort_date', 'source_collection', 'source_created', 'source_modified', 'subject', 'subject_headings', 'subjects', 'thumb_gallery', 'timestamp', 'title', 'type', 'unrestricted', 'url'])\n"
     ]
    }
   ],
   "source": [
    "#Confirming the structure of json for a single image\n",
    "image_request = request_link(formatted_links[0][0])\n",
    "print(image_request['item'].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = {} #Our dictionary for storing metadata, to be converted into a JSON file\n",
    "\n",
    "\n",
    "# counter = 0 #Each image will be given an index for organization purposes -- IN PROGRESS, MIGHT USE LCCN INSTEAD\n",
    "\n",
    "#We'll limit the amount of links we process here for a faster runtime\n",
    "for i,link in enumerate(formatted_links[:number_of_instances]):\n",
    "    # if i%10 == 0 and i !=0:\n",
    "    #     sleep(10)\n",
    "\n",
    "    try:\n",
    "        json_results = request_link(link[0])\n",
    "        #Filter by Washington, D.C. and images that can be freely distributed and used.\n",
    "\n",
    "        if 'No known restrictions' in json_results['item']['item']['rights_advisory'] and json_results['item']['item']['rights_information']:\n",
    "            if 'D.C.' or 'District of Columbia' in json_results['item']['item']['title'] or json_results['item']['item']['location']:\n",
    "                #ID:\n",
    "                id = json_results['item']['number_lccn']\n",
    "                #Title:\n",
    "                title = json_results['item']['title']\n",
    "                #URL:\n",
    "                url = json_results['item']['image_url']\n",
    "                #Subjects:\n",
    "                subjects = json_results['item']['subject_headings']\n",
    "                #Date:\n",
    "                date = json_results['item']['date']\n",
    "                #Contributors:\n",
    "                contributors = json_results['item']['contributor_names']\n",
    "                #Description:\n",
    "                description = json_results['item']['description']\n",
    "                #Collection:\n",
    "                collection = json_results['item']['source_collection']\n",
    "                #Original Format:\n",
    "                original_format = json_results['item']['original_format']\n",
    "\n",
    "                image_name = f\"image_{id[0]}.jpg\"\n",
    "                metadata_dict.update({\n",
    "                    image_name: {\n",
    "                    \"resource_id\": id[0],\n",
    "                    \"title\": title,\n",
    "                    \"item_url\" : url[-1],\n",
    "                    \"subjects\": subjects,\n",
    "                    \"dates\": date,\n",
    "                    \"contributors\": contributors,\n",
    "                    \"description\": description,\n",
    "                    \"alt_text\": link[1],\n",
    "                    \"collection\": collection,\n",
    "                    \"original_format\": original_format\n",
    "                    }\n",
    "                \n",
    "                })\n",
    "                # counter += 1\n",
    "\n",
    "    except:\n",
    "        error_links.append(link[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's move onto the collections without alt text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection_data in json_responses_no_alt:\n",
    "    results = collection_data['content']['results']\n",
    "    for result in results[:number_of_instances]:\n",
    "        # Again, limiting the data returned for faster processing.\n",
    "\n",
    "        #Filter by Washington, D.C. and images that can be freely distributed and used.\n",
    "        if 'No Known restrictions' in result['item']['rights_advisory'] or result['item']['rights_information']:\n",
    "            if 'D.C.' or 'District of Columbia' in result['item']['title'] or result['item']['notes'][:]:\n",
    "\n",
    "                #As the fields of collections can be varied, we have to check which fields are included\n",
    "                #with certain images\n",
    "                #ID:\n",
    "                id = result['number_lccn']\n",
    "                #Title:\n",
    "                title = result['title']\n",
    "                #URL:\n",
    "                url = result['image_url']\n",
    "                #Subjects:\n",
    "                if 'subject_heading' in result.keys():\n",
    "                    subjects = result['subject']\n",
    "                else:\n",
    "                    subjects = \"NA\"\n",
    "                #Date:\n",
    "                if 'date' in result.keys():\n",
    "                    date = result['date']\n",
    "                else:\n",
    "                    date = \"NA\"\n",
    "                #Contributors:\n",
    "                if 'contributor' in result.keys():\n",
    "                    contributors = result['contributor']\n",
    "                else:\n",
    "                    contributors = \"NA\"\n",
    "                #Description:\n",
    "                if 'description' in result.keys():\n",
    "                    description = result['description']\n",
    "                else:\n",
    "                    description = \"NA\"\n",
    "                #Collection:\n",
    "                if 'partof' in result.keys():\n",
    "                    collection = result['partof']\n",
    "                else:\n",
    "                    collection = \"NA\"\n",
    "                #Original Format:\n",
    "                original_format = result['original_format']\n",
    "            \n",
    "                image_name = f\"image_{id[0]}.jpg\"\n",
    "                metadata_dict.update({\n",
    "                    image_name: {\n",
    "                        \"resource_id\": id[0],\n",
    "                        \"title\": title,\n",
    "                        \"item_url\": url[-1],\n",
    "                        \"subjects\": subjects,\n",
    "                        \"dates\": date,\n",
    "                        \"contributors\": contributors,\n",
    "                        \"description\": description,\n",
    "                        \"alt_text\": link[1],\n",
    "                        \"collection\": collection,\n",
    "                        \"original_format\": original_format\n",
    "                    }\n",
    "                })\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, let's create a folder to store the images after we download them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('image-collection-output'):\n",
    "    os.mkdir('image-collection-output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the metadata dictionary let's download the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: image_2017686730.jpg\n",
      "Saved: image_2011630889.jpg\n",
      "Saved: image_2017687007.jpg\n",
      "Saved: image_2018703447.jpg\n",
      "Saved: image_2023632670.jpg\n",
      "Saved: image_2019689231.jpg\n",
      "Saved: image_2020742127.jpg\n",
      "Saved: image_2017879462.jpg\n",
      "Saved: image_2016826637.jpg\n",
      "Saved: image_2011631485.jpg\n",
      "Saved: image_2020742358.jpg\n",
      "Saved: image_2010648441.jpg\n",
      "Saved: image_2017661007.jpg\n",
      "Saved: image_2020714546.jpg\n",
      "Saved: image_2018698633.jpg\n",
      "Saved: image_2014633196.jpg\n",
      "Saved: image_2018700461.jpg\n",
      "Saved: image_2010630073.jpg\n",
      "Saved: image_2017647455.jpg\n",
      "Saved: image_2017702122.jpg\n",
      "Saved: image_2013630622.jpg\n",
      "Saved: image_2010637045.jpg\n",
      "Saved: image_2020721404.jpg\n",
      "Saved: image_2014630613.jpg\n",
      "Saved: image_2004661541.jpg\n",
      "Saved: image_2017732234.jpg\n",
      "Saved: image_2020734020.jpg\n",
      "Saved: image_2010630399.jpg\n",
      "Saved: image_2017882233.jpg\n",
      "Saved: image_2008680192.jpg\n",
      "Saved: image_2015652321.jpg\n",
      "Saved: image_2019708497.jpg\n",
      "Saved: image_2021643419.jpg\n",
      "Saved: image_2020732637.jpg\n",
      "Saved: image_2020733354.jpg\n",
      "Saved: image_2021638548.jpg\n",
      "Saved: image_93511941.jpg\n",
      "Saved: image_2004668297.jpg\n",
      "Saved: image_97518968.jpg\n",
      "Saved: image_2010651699.jpg\n",
      "Saved: image_00652544.jpg\n",
      "Saved: image_2002710466.jpg\n",
      "Saved: image_99471841.jpg\n",
      "Saved: image_96508832.jpg\n",
      "Saved: image_89709659.jpg\n",
      "Saved: image_2003680152.jpg\n",
      "Saved: image_98507080.jpg\n",
      "Saved: image_2006681388.jpg\n",
      "Saved: image_97502654.jpg\n",
      "Saved: image_2003669736.jpg\n",
      "Saved: image_2002705621.jpg\n",
      "Saved: image_96508557.jpg\n",
      "Saved: image_2005690021.jpg\n",
      "Saved: image_2002724022.jpg\n",
      "Saved: image_2003666590.jpg\n",
      "Saved: image_2003666591.jpg\n",
      "Saved: image_95512849.jpg\n",
      "Saved: image_95512864.jpg\n",
      "Saved: image_2003662267.jpg\n",
      "Saved: image_2002705861.jpg\n",
      "Saved: image_00652557.jpg\n",
      "Saved: image_2015631182.jpg\n",
      "Saved: image_2016631653.jpg\n",
      "Saved: image_2016631654.jpg\n",
      "Saved: image_2016631655.jpg\n",
      "Saved: image_2016631656.jpg\n",
      "Saved: image_2016631657.jpg\n",
      "Saved: image_2016631658.jpg\n",
      "Saved: image_2016631659.jpg\n",
      "Saved: image_2016631660.jpg\n",
      "Saved: image_2016631661.jpg\n",
      "Saved: image_2016631662.jpg\n",
      "Saved: image_2016631663.jpg\n",
      "Saved: image_2016631664.jpg\n",
      "Saved: image_2016631665.jpg\n",
      "Saved: image_2016631666.jpg\n",
      "Saved: image_2016631667.jpg\n",
      "Saved: image_2016631668.jpg\n",
      "Saved: image_2016631669.jpg\n",
      "Saved: image_2016631670.jpg\n",
      "Saved: image_2016631671.jpg\n",
      "Saved: image_2016631672.jpg\n",
      "Saved: image_2016631673.jpg\n",
      "Saved: image_2016631674.jpg\n",
      "Saved: image_2016631675.jpg\n",
      "Saved: image_2016631676.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for item in metadata_dict:\n",
    "    try:\n",
    "        item_data = metadata_dict[item]\n",
    "        id = item_data[\"resource_id\"]\n",
    "        image = requests.get(item_data[\"item_url\"])\n",
    "        image_filename = f\"image-collection-output/image_{id}.jpg\"\n",
    "        img_bytes_io = BytesIO(image.content)\n",
    "        converted_file = Image.open(img_bytes_io).convert('RGB').save(image_filename)\n",
    "        print(f\"Saved: {item}\")\n",
    "    except:\n",
    "        print(f\"Failed to Save: {item} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the JSON File\n",
    "\n",
    "Now that we've collected and organized all the metadata into Python dictionaries, we can convert metadata_dict to a JSON file and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"items_metadata.json\", 'w') as f:\n",
    "        json.dump(metadata_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is complete!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LOC)",
   "language": "python",
   "name": "loc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
