{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 run each of the models and have them output images generated into a separate folder --- unique to the model name\n",
    "\n",
    "# Faster R-CNN\n",
    "# FCOS\n",
    "# RetinaNet\n",
    "# SSD\n",
    "# SSDlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Utilities\n",
    "import os\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import ImageFont, ImageDraw\n",
    "from IPython.display import display\n",
    "import regex as re\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Importing the Models and their respective weights\n",
    "from torchvision.models.detection import (\n",
    "    # Faster R-CNN\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    # # FCOS\n",
    "    fcos_resnet50_fpn,\n",
    "    FCOS_ResNet50_FPN_Weights,\n",
    "    # RetinaNet\n",
    "    retinanet_resnet50_fpn_v2,\n",
    "    RetinaNet_ResNet50_FPN_V2_Weights,\n",
    "    # SSD\n",
    "    ssd300_vgg16,\n",
    "    SSD300_VGG16_Weights,\n",
    "    # SSDlite\n",
    "    ssdlite320_mobilenet_v3_large,\n",
    "    SSDLite320_MobileNet_V3_Large_Weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(\n",
    "    model, weights, image_path, output_directory=\"outputs\", threshold=0.9\n",
    "):\n",
    "    img = read_image(image_path)\n",
    "    font_path = os.path.abspath(\"fonts/OpenSans-Regular.ttf\")\n",
    "    font = ImageFont.truetype(font_path, 30)\n",
    "    # Step 1: Initialize model with the best available weights\n",
    "    weights = weights.DEFAULT\n",
    "    model_name = model.__name__\n",
    "    model = model(weights=weights, box_score_thresh=threshold)\n",
    "    model.eval()\n",
    "\n",
    "    # Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = [preprocess(img)]\n",
    "\n",
    "    # Step 4: Use the model and visualize the prediction\n",
    "    prediction = model(batch)[0]\n",
    "    labels = [weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels_with_scores = [\n",
    "        f\"{label} {score:.2f}\" for label, score in zip(labels, scores)\n",
    "    ]\n",
    "\n",
    "    box = draw_bounding_boxes(\n",
    "        img,\n",
    "        boxes=prediction[\"boxes\"],\n",
    "        labels=labels_with_scores,\n",
    "        colors=\"red\",\n",
    "        width=4,\n",
    "        font=font_path,\n",
    "        font_size=20,\n",
    "    )\n",
    "    im = to_pil_image(box.detach())\n",
    "\n",
    "    # Draw the model name at the bottom right of the image\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.text((5, 5), model_name, font=font, fill=(57, 255, 20), align=\"left\")\n",
    "\n",
    "    # creating the general output dirctory\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # creating the model's output directory:\n",
    "    model_output_directory = os.path.join(output_directory, model_name)\n",
    "    if not os.path.exists(model_output_directory):\n",
    "        os.makedirs(model_output_directory)\n",
    "    # extracting the image base name:\n",
    "    base_name = os.path.basename(image_path)\n",
    "\n",
    "    # creating the full image output file name\n",
    "    output_path = os.path.join(model_output_directory, base_name)\n",
    "    print(f\"Model Output saved to {output_path}\")\n",
    "    im.save(output_path, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image_1.jpg', 'image_2.jpg', 'image_3.jpg', 'image_4.jpg', 'image_5.jpg']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort images by their number\n",
    "def extract_number(filename):\n",
    "    match = re.findall(r\"\\d+\", filename)\n",
    "    if match:\n",
    "        return int(match[0])\n",
    "    return float(\"inf\")\n",
    "\n",
    "\n",
    "sorted_filenames = sorted(os.listdir(\"images\"), key=extract_number)\n",
    "# Printing out the sorted file names\n",
    "sorted_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_1.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_1.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_1.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_1.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aisaiahpellecer/Desktop/LOC/loc-env/lib/python3.9/site-packages/torchvision/utils.py:209: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_2.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_2.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_2.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_2.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_2.jpg\n",
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_3.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_3.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_3.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_3.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_3.jpg\n",
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_4.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_4.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_4.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_4.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_4.jpg\n",
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_5.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_5.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_5.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_5.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_5.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in sorted_filenames[:5]:\n",
    "    path = \"images/\" + image\n",
    "\n",
    "    object_detection(\n",
    "        fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, path\n",
    "    )\n",
    "    object_detection(fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, path)\n",
    "\n",
    "    object_detection(retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, path)\n",
    "\n",
    "    object_detection(ssd300_vgg16, SSD300_VGG16_Weights, path)\n",
    "\n",
    "    object_detection(\n",
    "        ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read images from computer\n",
    "folders = os.listdir(\"outputs/\")\n",
    "# image\n",
    "val = 1\n",
    "grid_number = len(os.listdir(\"outputs/fasterrcnn_resnet50_fpn_v2\"))\n",
    "for grid_image in range(grid_number):\n",
    "    image_vars = []\n",
    "    for i, folder in enumerate(os.listdir(\"outputs/\")):\n",
    "        sub_name = \"outputs/\" + folder\n",
    "        sub_directory = os.listdir(sub_name)\n",
    "        # print(sub_directory[0])\n",
    "        image_vars.append(read_image(sub_name + \"/\" + sub_directory[grid_image]))\n",
    "\n",
    "    Grid = make_grid(image_vars)\n",
    "    img = torchvision.transforms.ToPILImage()(Grid)\n",
    "\n",
    "    if not os.path.exists(\"model_panoramas\"):\n",
    "        os.makedirs(\"model_panoramas\")\n",
    "\n",
    "    panorama_name = \"model_panoramas/image\" + str(val) + \".jpg\"\n",
    "    img.save(panorama_name, \"JPEG\")\n",
    "    val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
