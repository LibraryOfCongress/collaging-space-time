{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations\n",
    "### Objectives\n",
    "\n",
    "This project involves a complete script/notebook that processes a set of sample images for object detection, annotating each image with bounding boxes, labels, and confidence scores for all detected objects. The project includes the following key components:\n",
    "* *Image Processing:* The script reads our set of sample images to be used for object detection.\n",
    "    * Note: For now the script runs on an experimental sample set, but more to come...\n",
    "\n",
    "* *Object Detection:* Multiple pre-trained models are utilized to detect objects within the images.\n",
    "\n",
    "    * Faster R-CNN\n",
    "    * FCOS\n",
    "    * RetinaNet\n",
    "    * SSD\n",
    "    * SSDlite\n",
    "\n",
    "* *Visualization:* The results of the object detection are visualized with a side-by-side comparison of the annotated images from each model. Comparisions look at the top 5 predictions from each model and their respective bounding boxes on the same image.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    "Note: this is a lot imports. If this is the first time that you running the notebook, it may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'regex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFont, ImageDraw\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mregex\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_grid\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'regex'"
     ]
    }
   ],
   "source": [
    "# Importing Utilities\n",
    "import os\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import ImageFont, ImageDraw\n",
    "from IPython.display import display\n",
    "import regex as re\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Importing the Models and their respective weights\n",
    "from torchvision.models.detection import (\n",
    "    # Faster R-CNN\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    # # FCOS\n",
    "    fcos_resnet50_fpn,\n",
    "    FCOS_ResNet50_FPN_Weights,\n",
    "    # RetinaNet\n",
    "    retinanet_resnet50_fpn_v2,\n",
    "    RetinaNet_ResNet50_FPN_V2_Weights,\n",
    "    # SSD\n",
    "    ssd300_vgg16,\n",
    "    SSD300_VGG16_Weights,\n",
    "    # SSDlite\n",
    "    ssdlite320_mobilenet_v3_large,\n",
    "    SSDLite320_MobileNet_V3_Large_Weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(\n",
    "    model, weights, image_path, output_directory=\"outputs\", threshold=0.9\n",
    "):\n",
    "    img = read_image(image_path)\n",
    "    font_path = os.path.abspath(\"fonts/OpenSans-Regular.ttf\")\n",
    "    font = ImageFont.truetype(font_path, 30)\n",
    "    # Step 1: Initialize model with the best available weights\n",
    "    weights = weights.DEFAULT\n",
    "    model_name = model.__name__\n",
    "\n",
    "    model = model(weights=weights, box_score_thresh=threshold)\n",
    "    model.eval()\n",
    "\n",
    "    # Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = [preprocess(img)]\n",
    "\n",
    "    # Step 4: Use the model and visualize the prediction\n",
    "    prediction = model(batch)[0]\n",
    "    labels = [weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels_with_scores = [\n",
    "        f\"{label} {score:.2f}\" for label, score in zip(labels, scores)\n",
    "    ]\n",
    "\n",
    "    box = draw_bounding_boxes(\n",
    "        img,\n",
    "        boxes=prediction[\"boxes\"],\n",
    "        labels=labels_with_scores,\n",
    "        colors=\"red\",\n",
    "        width=4,\n",
    "        font=font_path,\n",
    "        font_size=20,\n",
    "    )\n",
    "    im = to_pil_image(box.detach())\n",
    "\n",
    "    # Draw the model name at the bottom right of the image\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.text((5, 5), model_name, font=font, fill=(57, 255, 20), align=\"left\")\n",
    "\n",
    "    # creating the general output dirctory\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # creating the model's output directory:\n",
    "    model_output_directory = os.path.join(output_directory, model_name)\n",
    "    if not os.path.exists(model_output_directory):\n",
    "        os.makedirs(model_output_directory)\n",
    "    # extracting the image base name:\n",
    "    base_name = os.path.basename(image_path)\n",
    "\n",
    "    # creating the full image output file name\n",
    "    output_path = os.path.join(model_output_directory, base_name)\n",
    "    print(f\"Model Output saved to {output_path}\")\n",
    "    im.save(output_path, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(match[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m sorted_filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m), key\u001b[38;5;241m=\u001b[39mextract_number)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Printing out the sorted file names\u001b[39;00m\n\u001b[1;32m     11\u001b[0m sorted_filenames\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Sort images by their number\n",
    "def extract_number(filename):\n",
    "    match = re.findall(r\"\\d+\", filename)\n",
    "    if match:\n",
    "        return int(match[0])\n",
    "    return float(\"inf\")\n",
    "\n",
    "\n",
    "sorted_filenames = sorted(os.listdir(\"images\"), key=extract_number)\n",
    "# Printing out the sorted file names\n",
    "sorted_filenames[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_1.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_1.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_1.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_1.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aisaiahpellecer/Desktop/LOC/loc-env/lib/python3.9/site-packages/torchvision/utils.py:209: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_2.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_2.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_2.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_2.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_2.jpg\n",
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_3.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_3.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_3.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_3.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_3.jpg\n",
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_4.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_4.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_4.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_4.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_4.jpg\n",
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_5.jpg\n",
      "Model Output saved to outputs/fcos_resnet50_fpn/image_5.jpg\n",
      "Model Output saved to outputs/retinanet_resnet50_fpn_v2/image_5.jpg\n",
      "Model Output saved to outputs/ssd300_vgg16/image_5.jpg\n",
      "Model Output saved to outputs/ssdlite320_mobilenet_v3_large/image_5.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in sorted_filenames[:5]:\n",
    "    path = \"images/\" + image\n",
    "\n",
    "    object_detection(\n",
    "        fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, path\n",
    "    )\n",
    "    object_detection(fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, path)\n",
    "\n",
    "    object_detection(retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, path)\n",
    "\n",
    "    object_detection(ssd300_vgg16, SSD300_VGG16_Weights, path)\n",
    "\n",
    "    object_detection(\n",
    "        ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read images from computer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m folders \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# image\u001b[39;00m\n\u001b[1;32m      4\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# read images from computer\n",
    "folders = os.listdir(\"outputs/\")\n",
    "# image\n",
    "val = 1\n",
    "grid_number = len(os.listdir(\"outputs/fasterrcnn_resnet50_fpn_v2\"))\n",
    "for grid_image in range(grid_number):\n",
    "    image_vars = []\n",
    "    for i, folder in enumerate(os.listdir(\"outputs/\")):\n",
    "        sub_name = \"outputs/\" + folder\n",
    "        sub_directory = os.listdir(sub_name)\n",
    "        # print(sub_directory[0])\n",
    "        image_vars.append(read_image(sub_name + \"/\" + sub_directory[grid_image]))\n",
    "\n",
    "    Grid = make_grid(image_vars)\n",
    "    img = torchvision.transforms.ToPILImage()(Grid)\n",
    "\n",
    "    if not os.path.exists(\"model_panoramas\"):\n",
    "        os.makedirs(\"model_panoramas\")\n",
    "\n",
    "    panorama_name = \"model_panoramas/image\" + str(val) + \".jpg\"\n",
    "    img.save(panorama_name, \"JPEG\")\n",
    "    print(f\"Model Comparison saved as {panorama_name}\")\n",
    "    val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
