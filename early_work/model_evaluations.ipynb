{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Evaluations**\n",
    "### **Objectives**\n",
    "\n",
    "This project involves a complete script/notebook that processes a set of sample images for object detection, annotating each image with bounding boxes, labels, and confidence scores for all detected objects. The project includes the following key components:\n",
    "* *Image Processing:* The script reads our set of sample images to be used for object detection.\n",
    "    * Note: For now the script runs on an experimental sample set, but more to come...\n",
    "\n",
    "* *Object Detection:* Multiple pre-trained models are utilized to detect objects within the images.\n",
    "\n",
    "    * Faster R-CNN\n",
    "    * FCOS\n",
    "    * RetinaNet\n",
    "    * SSD\n",
    "    * SSDlite\n",
    "\n",
    "* *Visualization:* The results of the object detection are visualized with a side-by-side comparison of the annotated images from each model. Comparisions look at the top 5 predictions from each model and their respective bounding boxes on the same image.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Imports**\n",
    "\n",
    "Note: this is a lot imports. If this is the first time that you running the notebook, it may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Utilities\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes, make_grid\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# Importing the Models and their respective weights\n",
    "from torchvision.models.detection import (\n",
    "    # Faster R-CNN\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    # # FCOS\n",
    "    fcos_resnet50_fpn,\n",
    "    FCOS_ResNet50_FPN_Weights,\n",
    "    # RetinaNet\n",
    "    retinanet_resnet50_fpn_v2,\n",
    "    RetinaNet_ResNet50_FPN_V2_Weights,\n",
    "    # SSD\n",
    "    ssd300_vgg16,\n",
    "    SSD300_VGG16_Weights,\n",
    "    # SSDlite\n",
    "    ssdlite320_mobilenet_v3_large,\n",
    "    SSDLite320_MobileNet_V3_Large_Weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **save_image_with_title function**\n",
    "This function creates an output directory and subdirectories. In addition, it saves the images to a corresponding model subdirectories using the following:\n",
    "* *title*: The title of the Model's Output: **Top Detections of the {model_name}: {score_len} detections at {threshold}**\n",
    "* *output_path*: The main directory where you want to save the output image.\n",
    "* *model_name*: The name of the model, used to create a subdirectory. \n",
    "* *image_path*: The original image path. The function extracts the base name of the image.\n",
    "* *im*: Model modified or unmodified PIL Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_with_title(title, image, output_path, model_name, image_path):\n",
    "    # Convert the PIL image to a format that Matplotlib can handle\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # creating the model's output directory\n",
    "    model_output_directory = os.path.join(output_path, model_name)\n",
    "    if not os.path.exists(model_output_directory):\n",
    "        os.makedirs(model_output_directory)\n",
    "    base_name = os.path.basename(image_path)\n",
    "    output_file = os.path.join(model_output_directory, base_name)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(output_file, bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    plt.close()\n",
    "    print(f\"Model Output saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **object_detection function**\n",
    "This function generates the input model, processes the input image using model weights, and outputs the a visualization of the model's prediction (as annotated bounding boxes) to an output path.\n",
    "* *model*: model from *torchvision.models.detection*. This should already be imported.\n",
    "* *weights*: weights that correspond to model. Review torchvision model documentation.\n",
    "* *image_path*: original image path.\n",
    "* *output_path*: The main directory where you want to save the output image. DEFAULT= \"evaluation/outputs\".\n",
    "* *threshold*: model probability score threshold. DEFAULT= 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(\n",
    "    model, weights, image_path, output_path=\"evaluation/outputs\", threshold=0.90\n",
    "):\n",
    "    img = read_image(image_path)\n",
    "    # Step 1: Initialize model with the best available weights\n",
    "    weights = weights.DEFAULT\n",
    "    model_name = model.__name__\n",
    "\n",
    "    model = model(weights=weights)\n",
    "    model.eval()\n",
    "\n",
    "    # Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = [preprocess(img)]\n",
    "\n",
    "    # Step 4: Use the model and visualize the prediction\n",
    "    prediction = model(batch)[0]\n",
    "\n",
    "    # Extracting the len of Index of the scores that meet the threshold value:\n",
    "    score_len = (prediction[\"scores\"] >= threshold).sum().item()\n",
    "    # Limits the scores at the threshold to just the top 5\n",
    "    if score_len >= 5:\n",
    "        score_len = 5\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Step 5: Visualizing Model predictions onto image.\n",
    "\n",
    "    # Annotation features\n",
    "    title = f\"Evaluating Top Detections\\n{model_name}\\n{score_len} detections at {threshold}\"\n",
    "    fill = (170, 51, 106)\n",
    "    font_path = os.path.abspath(\"fonts/OpenSans-Regular.ttf\")\n",
    "    font = ImageFont.truetype(font_path, 30)\n",
    "\n",
    "    if score_len == 0:  # If there are no predictions at the threshold, just o\n",
    "        im = to_pil_image(img)\n",
    "\n",
    "    else:  # If there are predictions, generate annotated visualization and save to corresponding output directory\n",
    "        labels = [\n",
    "            weights.meta[\"categories\"][i] for i in prediction[\"labels\"][:score_len]\n",
    "        ]\n",
    "        scores = prediction[\"scores\"][:score_len]\n",
    "        labels_with_scores = [\n",
    "            f\"{label} {score:.2f}\" for label, score in zip(labels, scores)\n",
    "        ]\n",
    "\n",
    "        box = draw_bounding_boxes(\n",
    "            img,\n",
    "            boxes=prediction[\"boxes\"][:score_len],\n",
    "            labels=labels_with_scores,\n",
    "            colors=\"red\",\n",
    "            width=4,\n",
    "            font=font_path,\n",
    "            font_size=25,\n",
    "        )\n",
    "        im = to_pil_image(box.detach())\n",
    "\n",
    "    save_image_with_title(title, im, output_path, model_name, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **extract_number function**\n",
    "This function returns a sorted list of the files in a directory by extracting the number in the file names.\n",
    "* *directory_name*: name of directory with the files you need sorted. Note: this only works if the files already have some unique numerical ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(directory_name):\n",
    "    match = re.findall(r\"\\d+\", directory_name)\n",
    "    # if match:\n",
    "    return int(match[0])\n",
    "    # return float(\"inf\")\n",
    "\n",
    "\n",
    "# Creating a sorted list of the filenames from my images dir\n",
    "sorted_filenames = sorted(os.listdir(\"images\"), key=extract_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code goes through the sorted image file names and saves annotated images of the predictions accross each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_00650358.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_00650358.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_00650358.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_00650358.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_00650358.jpg\n",
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_00650363.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_00650363.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_00650363.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_00650363.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_00650363.jpg\n",
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_00650921.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_00650921.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_00650921.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_00650921.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_00650921.jpg\n",
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_00650923.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_00650923.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_00650923.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_00650923.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_00650923.jpg\n",
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_00650930.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_00650930.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_00650930.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_00650930.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_00650930.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in sorted_filenames[:5]:\n",
    "    path = \"images/\" + image\n",
    "\n",
    "    object_detection(\n",
    "        fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, path\n",
    "    )\n",
    "    object_detection(fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, path)\n",
    "\n",
    "    object_detection(retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, path)\n",
    "\n",
    "    object_detection(ssd300_vgg16, SSD300_VGG16_Weights, path)\n",
    "\n",
    "    object_detection(\n",
    "        ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code generates and saves a grid comparision image of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_2016887160.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_2016887160.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_2016887160.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_2016887160.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_2016887160.jpg\n",
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_2017879462.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_2017879462.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_2017879462.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_2017879462.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_2017879462.jpg\n",
      "Model Output saved to evaluation/outputs/fasterrcnn_resnet50_fpn_v2/image_2021643419.jpg\n",
      "Model Output saved to evaluation/outputs/fcos_resnet50_fpn/image_2021643419.jpg\n",
      "Model Output saved to evaluation/outputs/retinanet_resnet50_fpn_v2/image_2021643419.jpg\n",
      "Model Output saved to evaluation/outputs/ssd300_vgg16/image_2021643419.jpg\n",
      "Model Output saved to evaluation/outputs/ssdlite320_mobilenet_v3_large/image_2021643419.jpg\n"
     ]
    }
   ],
   "source": [
    "# Extra Paths for the Sake of Documentation:\n",
    "extra_paths = [\n",
    "    \"images/image_2016887160.jpg\",\n",
    "    \"../workflow/image-collection-output/image_2017879462.jpg\",\n",
    "    \"../workflow/image-collection-output/image_2021643419.jpg\",\n",
    "]\n",
    "\n",
    "for path in extra_paths:\n",
    "    object_detection(\n",
    "        fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, path\n",
    "    )\n",
    "    object_detection(fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, path)\n",
    "\n",
    "    object_detection(retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, path)\n",
    "\n",
    "    object_detection(ssd300_vgg16, SSD300_VGG16_Weights, path)\n",
    "\n",
    "    object_detection(\n",
    "        ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_2021643419.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_2016887160.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_00650923.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_00650921.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_2017879462.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_00650930.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_00650363.jpg\n",
      "Model Comparison saved as evaluation/model_comparisons/comparison_image_00650358.jpg\n"
     ]
    }
   ],
   "source": [
    "# read images from computer\n",
    "eval_outputs_dir = \"../early_work/evaluation/outputs/\"\n",
    "\n",
    "folders = os.listdir(eval_outputs_dir)\n",
    "# image\n",
    "grid_number = len(os.listdir(eval_outputs_dir + \"fasterrcnn_resnet50_fpn_v2\"))\n",
    "for grid_image in range(grid_number):\n",
    "    image_vars = []\n",
    "    for i, folder in enumerate(os.listdir(eval_outputs_dir)):\n",
    "        if folder != \".DS_Store\":\n",
    "            sub_name = eval_outputs_dir + folder\n",
    "            sub_directory = os.listdir(sub_name)\n",
    "            # print(sub_directory[0])\n",
    "            file_name = sub_name + \"/\" + sub_directory[grid_image]\n",
    "            image_vars.append(read_image(file_name))\n",
    "\n",
    "        base_name = os.path.basename(file_name)\n",
    "        Grid = make_grid(image_vars)\n",
    "        img = torchvision.transforms.ToPILImage()(Grid)\n",
    "\n",
    "        comparison_dir = \"evaluation/\" + \"model_comparisons\"\n",
    "        if not os.path.exists(comparison_dir):\n",
    "            os.makedirs(comparison_dir)\n",
    "\n",
    "    panorama_name = comparison_dir + \"/comparison_\" + base_name\n",
    "    img.save(panorama_name, \"JPEG\")\n",
    "    print(f\"Model Comparison saved as {panorama_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LOC)",
   "language": "python",
   "name": "loc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
