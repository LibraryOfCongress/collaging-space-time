{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 run each of the models and have them output images generated into a separate folder --- unique to the model name\n",
    "\n",
    "# Faster R-CNN\n",
    "# FCOS\n",
    "# RetinaNet\n",
    "# SSD\n",
    "# SSDlite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.models.detection import (\n",
    "    # Faster R-CNN\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    "    FasterRCNN_ResNet50_FPN_V2_Weights,\n",
    "    # FCOS\n",
    "    fcos_resnet50_fpn,\n",
    "    FCOS_ResNet50_FPN_Weights,\n",
    "    # RetinaNet\n",
    "    retinanet_resnet50_fpn_v2,\n",
    "    RetinaNet_ResNet50_FPN_V2_Weights,\n",
    "    # SSD\n",
    "    ssd300_vgg16,\n",
    "    SSD300_VGG16_Weights,\n",
    "    # SSDlite\n",
    "    ssdlite320_mobilenet_v3_large,\n",
    "    SSDLite320_MobileNet_V3_Large_Weights\n",
    ")\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import ImageFont\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(\n",
    "    model, weights, image_path, output_directory=\"outputs\", threshold=0.9\n",
    "):\n",
    "    img = read_image(image_path)\n",
    "    font_path = os.path.abspath(\"fonts/OpenSans-Regular.ttf\")\n",
    "    # Step 1: Initialize model with the best available weights\n",
    "    weights = weights.DEFAULT\n",
    "    model_name = model.__name__\n",
    "    model = model(weights=weights, box_score_thresh=threshold)\n",
    "    model.eval()\n",
    "\n",
    "    # Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "    # Step 3: Apply inference preprocessing transforms\n",
    "    batch = [preprocess(img)]\n",
    "\n",
    "    # Step 4: Use the model and visualize the prediction\n",
    "    prediction = model(batch)[0]\n",
    "    labels = [weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n",
    "    scores = prediction[\"scores\"]\n",
    "    labels_with_scores = [\n",
    "        f\"{label} {score:.2f}\" for label, score in zip(labels, scores)\n",
    "    ]\n",
    "\n",
    "    box = draw_bounding_boxes(\n",
    "        img,\n",
    "        boxes=prediction[\"boxes\"],\n",
    "        labels=labels_with_scores,\n",
    "        colors=\"red\",\n",
    "        width=4,\n",
    "        font=font_path,\n",
    "        font_size=20,\n",
    "    )\n",
    "    im = to_pil_image(box.detach())\n",
    "\n",
    "    # creating the general output dirctory\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # creating the model's output directory:\n",
    "    model_output_directory = os.path.join(output_directory, model_name)\n",
    "    if not os.path.exists(model_output_directory):\n",
    "        os.makedirs(model_output_directory)\n",
    "    # extracting the image base name:\n",
    "    base_name = os.path.basename(image_path)\n",
    "\n",
    "    # creating the full image output file name\n",
    "    output_path = os.path.join(model_output_directory, base_name)\n",
    "    print(f\"Model Output saved to {output_path}\")\n",
    "    im.save(output_path, \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_15.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aisaiahpellecer/Desktop/lclabs-jfp24/loc_env/lib/python3.9/site-packages/torchvision/utils.py:209: UserWarning: boxes doesn't contain any box. No box was drawn\n",
      "  warnings.warn(\"boxes doesn't contain any box. No box was drawn\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output saved to outputs/fasterrcnn_resnet50_fpn_v2/image_29.jpg\n"
     ]
    }
   ],
   "source": [
    "for image in sorted((os.listdir(\"images\")[:2])):\n",
    "    path = \"images/\" + image\n",
    "\n",
    "    object_detection(\n",
    "        fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights, path\n",
    "    # )\n",
    "    # object_detection(fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights, path)\n",
    "\n",
    "    # object_detection(retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights, path)\n",
    "\n",
    "    # object_detection(ssd300_vgg16, SSD300_VGG16_Weights, path)\n",
    "\n",
    "    # object_detection(\n",
    "        # ssdlite320_mobilenet_v3_large, SSDLite320_MobileNet_V3_Large_Weights, path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
